import os
from transformers import AutoTokenizer, AutoProcessor
from qwen_vl_utils import process_vision_info
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from scipy.ndimage import zoom
import numpy as np
from tqdm import tqdm
import json
import torch.multiprocessing as mp
import multiprocessing
from joblib import Parallel, delayed
import time
import random
from PIL import Image
import io
import numpy as np
import base64
import gc
import base64
import multiprocessing
from multiprocessing import Pool
from accelerate import infer_auto_device_map, dispatch_model
import shutil
from inference import cycle_epoch_infer
import traceback
import subprocess

Image.MAX_IMAGE_PIXELS = 28000000000

def log_error(e):
    print(f"âŒ å¼‚å¸¸å‘ç”Ÿ: {e}")
    print(f"Traceback:\n{traceback.format_exc()}")

def get_available_gpus(max_memory_mb=1000, max_gpus=None):
    """
    è·å–æ˜¾å­˜å ç”¨ä½äº max_memory_mb çš„ GPU è®¾å¤‡ ID åˆ—è¡¨ï¼Œå¹¶æŒ‰å ç”¨ä»å°åˆ°å¤§æ’åºè¿”å›

    Args:
        max_memory_mb: æœ€å¤§å…è®¸æ˜¾å­˜å ç”¨ï¼ˆMBï¼‰ï¼Œä½äºæ­¤å€¼æ‰è®¤ä¸ºæ˜¯â€œå¯ç”¨â€
        max_gpus: æœ€å¤šè¿”å›å‡ ä¸ª GPUï¼ŒNone è¡¨ç¤ºè¿”å›æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„

    Returns:
        æŒ‰æ˜¾å­˜å ç”¨å‡åºæ’åˆ—çš„å¯ç”¨ GPU ID åˆ—è¡¨ï¼Œä¾‹å¦‚ [2, 0, 3]
    """
    try:
        # ä½¿ç”¨ nvidia-smi è·å–æ¯å¼  GPU çš„æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
        result = subprocess.run([
            'nvidia-smi', '--query-gpu=memory.used', '--format=csv,noheader,nounits'
        ], capture_output=True, text=True, check=True)
        
        # è§£ææ˜¾å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰
        used_memory = [int(x.strip()) for x in result.stdout.strip().split('\n')]
        
        # åˆ›å»º (gpu_id, memory_used) çš„åˆ—è¡¨å¹¶æŒ‰æ˜¾å­˜ä½¿ç”¨é‡å‡åºæ’åº
        gpu_memory_pairs = [(i, mem) for i, mem in enumerate(used_memory)]
        gpu_memory_pairs.sort(key=lambda x: x[1])  # æŒ‰æ˜¾å­˜ä½¿ç”¨é‡ä»å°åˆ°å¤§æ’åº
        
        # ç­›é€‰ä½äºé˜ˆå€¼çš„ GPUï¼Œå¹¶ä¿ç•™æ’åºé¡ºåº
        available_gpus = [gpu_id for gpu_id, mem in gpu_memory_pairs if mem < max_memory_mb]
        
        # é™åˆ¶è¿”å›æ•°é‡
        if max_gpus is not None:
            available_gpus = available_gpus[:max_gpus]
        
        return available_gpus

    except Exception as e:
        print(f"Error detecting GPU memory: {e}")
        return []

def main(datasetdir,savedir,max_pixels,Parallels,sig,thre,para_nums=6):
    if not Parallels: para_nums = 1
    dataset = load_dataset_Vstar_json(datasetdir)
    # dataset = load_dataset_hrbench_json(datasetdir)
    random.shuffle(dataset)
    available_gpus = get_available_gpus(max_memory_mb=1000, max_gpus=para_nums)
    if len(available_gpus) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç©ºé—² GPUï¼ˆå ç”¨æ˜¾å­˜ < 1000MB")
        return
    print(f"âœ… æ‰¾åˆ° {len(available_gpus)} ä¸ªå¯ç”¨ GPUï¼ˆå ç”¨æ˜¾å­˜ < 1000MBï¼‰: {available_gpus}")
    # åˆ†å‰²æ•°æ®é›†åˆ°ä¸åŒ GPU ä¸Š
    # å°† dataset åˆ’åˆ†ä¸º num_gpus ä»½ï¼Œæ¯ä»½å°½é‡å‡è¡¡
    splits = np.array_split(dataset, len(available_gpus))
    print("æ–‡ä»¶åŠ è½½å®Œæˆ")
    if not Parallels:
        for rank, gpu_id in tqdm(enumerate(available_gpus)):
            dataset_part = splits[rank]
            cycle_epoch_infer(gpu_id,rank,dataset_part,savedir,max_pixels,sig,thre)
    else:
        pool = Pool(processes=len(available_gpus))
        results = []
        for rank, gpu_id in tqdm(enumerate(available_gpus)):
            dataset_part = splits[rank]
            res = pool.apply_async(
                cycle_epoch_infer,
                args=(gpu_id,rank, dataset_part, savedir, max_pixels,sig,thre),
                error_callback=log_error
            )
            results.append(res)
        pool.close()
        # ç­‰å¾…å¹¶è·å–ç»“æœï¼ˆå¯é€‰ï¼šè·å–è¿”å›å€¼ï¼‰
        for res in tqdm(results, desc="ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ"):
            res.wait()  # è§¦å‘ error_callback
        pool.join()

if __name__ == "__main__":
    # ğŸ‘‡ å¿…é¡»æ”¾åœ¨è¿™é‡Œï¼
    mp.set_start_method('spawn', force=True)
    maxp = 16384
    Parallels = True
    sigma = [3]
    threshold = [0.7]
    seed = 2077
    random.seed(seed)
    current_time = time.localtime()
    formatted_time = time.strftime("%Y-%m-%d", current_time)
    datasetdir = f"Vstar.json"
    for ansatt_lenth in ansatt_lenths:
        savejson = f"Vstar_results.json"
        main(datasetdir,savejson,maxp,Parallels,sigma,threshold,4)
